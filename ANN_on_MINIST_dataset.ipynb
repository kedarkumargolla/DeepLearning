{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN on MINIST dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQrfCpTgSzT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "from torch import nn,optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wbkG-zZS3LI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "7bd685cc-9d43-4cd0-f98c-4674e44e3462"
      },
      "source": [
        "train_dataset = dsets.MNIST(root='./data', \n",
        "                            train=True, \n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data', \n",
        "                           train=False, \n",
        "                           transform=transforms.ToTensor())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 8581262.98it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 122316.48it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2019676.61it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 43374.42it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I_CrQqZS4DP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "num_epochs = 10\n",
        "n_iters = num_epochs*(len(train_dataset)/ batch_size)\n",
        "n_iters = int(n_iters)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiQNeqn6S4L7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 100)\n",
        "        self.fc2 = nn.Linear(100, 50)\n",
        "        self.fc3 = nn.Linear(50, 25)\n",
        "        self.fc4 = nn.Linear(25, 10)\n",
        "\n",
        "        # Dropout module with 0.2 drop probability\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "        '''\n",
        "         def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 50)\n",
        "        self.fc3 = nn.Linear(50, 25)\n",
        "        self.fc4 = nn.Linear(25, 10)\n",
        "\n",
        "        # Dropout module with 0.2 drop probability\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        '''\n",
        "\n",
        "    def forward(self, x):\n",
        "        # make sure input tensor is flattened\n",
        "        x = x.view(x.shape[0], -1)\n",
        "\n",
        "        # Now with dropout\n",
        "        #x = self.dropout(F.relu(self.fc1(x)))\n",
        "        #x = self.dropout(F.relu(self.fc2(x)))\n",
        "        #x = self.dropout(F.relu(self.fc3(x)))\n",
        "\n",
        "\n",
        "        x = self.dropout(F.logsigmoid(self.fc1(x)))\n",
        "        x = self.dropout(F.logsigmoid(self.fc2(x)))\n",
        "        x = self.dropout(F.logsigmoid(self.fc3(x)))\n",
        "        # output so no dropout here\n",
        "        x = F.log_softmax(self.fc4(x), dim=1)\n",
        "\n",
        "        return x\n",
        "        \n",
        "model=Network()\n",
        "#optimizer=optim.Adam(model.parameters(),lr=0.01)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.4)\n",
        "criterion=nn.NLLLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypHxMDZcS4JM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "8300815d-32c4-48eb-a692-9f171556336f"
      },
      "source": [
        "epochs=10\n",
        "train_losses,test_losses=[],[]\n",
        "for e in range(epochs):\n",
        "    running_loss=0\n",
        "    for images,labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        log_ps=model(images)\n",
        "        loss=criterion(log_ps,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss+=loss.item()\n",
        "        \n",
        "    else:\n",
        "        test_loss=0\n",
        "        accuracy=0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for images,labels in test_loader:\n",
        "                log_ps=model(images)\n",
        "                test_loss+=criterion(log_ps,labels)\n",
        "                ps=torch.exp(log_ps)\n",
        "                top_p,top_class=ps.topk(1,dim=1)\n",
        "                equals=top_class==labels.view(*top_class.shape)\n",
        "                accuracy+=torch.mean(equals.type(torch.FloatTensor))\n",
        "        model.train()\n",
        "        train_losses.append(running_loss/len(train_loader))\n",
        "        test_losses.append(test_loss/len(test_loader))\n",
        "\n",
        "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
        "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
        "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/10..  Training Loss: 2.316..  Test Loss: 2.294..  Test Accuracy: 0.114\n",
            "Epoch: 2/10..  Training Loss: 2.300..  Test Loss: 2.284..  Test Accuracy: 0.118\n",
            "Epoch: 3/10..  Training Loss: 2.277..  Test Loss: 2.217..  Test Accuracy: 0.271\n",
            "Epoch: 4/10..  Training Loss: 1.995..  Test Loss: 1.612..  Test Accuracy: 0.424\n",
            "Epoch: 5/10..  Training Loss: 1.593..  Test Loss: 1.289..  Test Accuracy: 0.525\n",
            "Epoch: 6/10..  Training Loss: 1.384..  Test Loss: 1.112..  Test Accuracy: 0.620\n",
            "Epoch: 7/10..  Training Loss: 1.201..  Test Loss: 0.868..  Test Accuracy: 0.719\n",
            "Epoch: 8/10..  Training Loss: 1.015..  Test Loss: 0.741..  Test Accuracy: 0.762\n",
            "Epoch: 9/10..  Training Loss: 0.927..  Test Loss: 0.684..  Test Accuracy: 0.782\n",
            "Epoch: 10/10..  Training Loss: 0.870..  Test Loss: 0.639..  Test Accuracy: 0.803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17UoGKCnS4Gd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bdd74676-8c71-4342-d6d3-4e66fcce7c4d"
      },
      "source": [
        "\n",
        "print(\"Our model: \\n\\n\", model, '\\n')\n",
        "\n",
        "\n",
        "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
        "pytorch_total_params\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our model: \n",
            "\n",
            " Network(\n",
            "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=50, bias=True)\n",
            "  (fc3): Linear(in_features=50, out_features=25, bias=True)\n",
            "  (fc4): Linear(in_features=25, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ") \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85085"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}